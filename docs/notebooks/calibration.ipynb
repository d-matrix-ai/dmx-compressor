{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demos how to do quantization calibration on INT formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmx.compressor.modeling.hf import pipeline\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"d-matrix/opt\",\n",
    "    revision=\"opt-125m\",\n",
    "    dmx_config=\"BASELINE\",\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",  # enabling model parallel on multi-GPU nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block configures the model to the right format.\n",
    "\n",
    "xxx_format takes a single value.\n",
    "\n",
    "input_formats takes a list or a dictionary. When a list is passed, the formats will be set in the order of the castTos within input_casts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmx.compressor.modeling import DmxConfigRule,nn\n",
    "format = \"XP[8,0](CSN)\"\n",
    "rules = (\n",
    "    DmxConfigRule(\n",
    "        module_types=(nn.Linear,),\n",
    "        module_config=dict(\n",
    "            input_formats=[format],  # option 1\n",
    "            # input_formats = {\"input_cast\": format} # option 2\n",
    "            weight_format=format,\n",
    "        ),\n",
    "    ),\n",
    "    DmxConfigRule(\n",
    "        module_types=(nn.ScaledDotProductAttention,),\n",
    "        module_config=dict(\n",
    "            input_formats=[format, format, format],  # option 1\n",
    "            # input_formats={\n",
    "            #     \"query_states_cast\": format,\n",
    "            #     \"key_states_cast\": format,\n",
    "            #     \"value_states_cast\": format,\n",
    "            #     \"attn_mask_cast\": None,\n",
    "            # },  # option 2\n",
    "            weight_format=format,\n",
    "        ),\n",
    "    ),\n",
    "    DmxConfigRule(\n",
    "        module_types=(nn.ActActMatMul,),\n",
    "        module_config=dict(\n",
    "            input_formats=[format, format],  # option 1\n",
    "            # input_formats = {\"input_cast\": format, \"multiplier_cast\":format} # option 2\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "# configure model based on rules\n",
    "pipe.model.configure(None, *rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: if the data format does not require calibration, all steps under this collapsed section can be skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forward pass needs to be done before calibration so that JIT transformation is triggered and dmx modules exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randint(1, 100, (1, 1024))\n",
    "with torch.no_grad():\n",
    "    y = pipe.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the content of the transformed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying layers to calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_layers_matmul = {\n",
    "    n: m for n, m in pipe.model.named_dmx_modules() if isinstance(m, nn.ActActMatMul)\n",
    "}\n",
    "calibration_layers_lin = {\n",
    "    n: m for n, m in pipe.model.named_dmx_modules() if isinstance(m, (nn.Linear,))\n",
    "}\n",
    "calibration_layers_attention = {\n",
    "    n: m\n",
    "    for n, m in pipe.model.named_dmx_modules()\n",
    "    if isinstance(m, (nn.ScaledDotProductAttention,))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying hyperparameters to use for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmx.compressor.numerical.observer import HistogramObserver, MinMaxObserver\n",
    "matmul_hyperparams = {\n",
    "    \"input_cast\": dict(\n",
    "        observer_cls=HistogramObserver,\n",
    "        qscheme_to_overload=None,\n",
    "        group_size=None,\n",
    "        ch_axis=None,\n",
    "    ),\n",
    "    \"multiplier_cast\": dict(\n",
    "        observer_cls=MinMaxObserver,\n",
    "        qscheme_to_overload=torch.per_channel_affine,\n",
    "        ch_axis=-2,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "if hyperparams=None, inside calibrating_activations method it defaults to\n",
    "```python\n",
    "{\n",
    "    \"input_cast\": dict(\n",
    "        observer_cls=HistogramObserver,\n",
    "        qscheme_to_overload=None,\n",
    "        group_size=None,\n",
    "        ch_axis=None,\n",
    "    ),\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_hyperparams = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if values of hyperparams are empty dicts, inside calibrating_activations method it defaults to \n",
    "``` python\n",
    "dict(\n",
    "    observer_cls=HistogramObserver,\n",
    "    qscheme_to_overload=None,\n",
    "    group_size=None,\n",
    "    ch_axis=None,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_hyperparams = {\n",
    "    \"query_states_cast\": {},\n",
    "    \"key_states_cast\": {},\n",
    "    \"value_states_cast\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), pipe.model.calibrating_weights(\n",
    "    calibration_layers_lin.items()\n",
    "), pipe.model.calibrating_activations(\n",
    "    calibration_layers_matmul.items(), matmul_hyperparams\n",
    "), pipe.model.calibrating_activations(\n",
    "    calibration_layers_lin.items(), lin_hyperparams\n",
    "), pipe.model.calibrating_activations(\n",
    "    calibration_layers_attention.items(), attention_hyperparams\n",
    "):\n",
    "    pipe.do_forward_on(dataset = \"wikitext\",dataset_version=\"wikitext-2-raw-v1\",column_name = \"text\",dataset_split=\"train\",num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pipe.evaluate(\n",
    "    \"d-matrix/dmx_perplexity\",\n",
    "    dataset=\"wikitext\",\n",
    "    dataset_version=\"wikitext-2-raw-v1\",\n",
    ")\n",
    "print(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
