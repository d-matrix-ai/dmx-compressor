{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58301fd",
   "metadata": {},
   "source": [
    "## Example ADVANCED mode recipe - normalization layer extra parameters tuning by SLaNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7acd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32146a0",
   "metadata": {},
   "source": [
    "\n",
    "1. Instantiate a `torch` model from source, HF hub in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65349518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.9988459348678589, 'label': 'a photo of cats'},\n",
       "  {'score': 0.0011540568666532636, 'label': 'a photo of dogs'}],\n",
       " [{'score': 0.9962789416313171, 'label': 'a kitchen scene'},\n",
       "  {'score': 0.0037210225127637386, 'label': 'a living room scene'}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = \"openai/clip-vit-base-patch32\"\n",
    "task = \"zero-shot-image-classification\"\n",
    "\n",
    "task_cases = [\n",
    "    dict(\n",
    "        images=\"http://images.cocodataset.org/val2017/000000039769.jpg\",\n",
    "        candidate_labels=[\n",
    "            \"a photo of cats\",\n",
    "            \"a photo of dogs\",\n",
    "        ],\n",
    "    ),\n",
    "    dict(\n",
    "        images=\"http://images.cocodataset.org/val2017/000000397133.jpg\",\n",
    "        candidate_labels=[\n",
    "            \"a kitchen scene\",\n",
    "            \"a living room scene\",\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "[pipe(**_tc) for _tc in task_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1ea08",
   "metadata": {},
   "source": [
    "2. Transform into `DmxModel`; this does not change the functional behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea78b5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.9988459348678589, 'label': 'a photo of cats'},\n",
       "  {'score': 0.0011540546547621489, 'label': 'a photo of dogs'}],\n",
       " [{'score': 0.9962789416313171, 'label': 'a kitchen scene'},\n",
       "  {'score': 0.003721001325175166, 'label': 'a living room scene'}]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dmx.compressor import DmxModel\n",
    "\n",
    "pipe.model = DmxModel.from_torch(pipe.model)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "[pipe(**_tc) for _tc in task_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d57ed5",
   "metadata": {},
   "source": [
    "3. Configure to BASIC mode; this should bring in all VSIMD approximations with default config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2de369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.843508780002594, 'label': 'a photo of cats'},\n",
       "  {'score': 0.1564912348985672, 'label': 'a photo of dogs'}],\n",
       " [{'score': 0.938322126865387, 'label': 'a kitchen scene'},\n",
       "  {'score': 0.061677876859903336, 'label': 'a living room scene'}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.to_basic_mode()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "[pipe(**_tc) for _tc in task_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db9d4f",
   "metadata": {},
   "source": [
    "4. SLaNC calibrate `LayerNorm` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288e70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLaNC done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.6110338568687439, 'label': 'a photo of cats'},\n",
       "  {'score': 0.3889661133289337, 'label': 'a photo of dogs'}],\n",
       " [{'score': 0.5365557670593262, 'label': 'a living room scene'},\n",
       "  {'score': 0.4634442627429962, 'label': 'a kitchen scene'}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dmx.compressor import nn\n",
    "from dmx.compressor.advanced_recipe import (\n",
    "    DmxSLaNCHyperparams,\n",
    "    DmxSLaNCRecipe,\n",
    ")\n",
    "\n",
    "\n",
    "def hp_gen(_model) -> dict:\n",
    "    _hp = {}    \n",
    "    for _n, _m in _model.named_dmx_modules():\n",
    "        if isinstance(_m, nn.LayerNorm):\n",
    "            if \"layer_norm1\" in _n:\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_attn\",\n",
    "                    prev_layer=pipe.model.get_submodule(_n.replace(\"layer_norm1\", \"self_attn\", -1)),\n",
    "                )\n",
    "            elif \"layer_norm2\" in _n:\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_mlp\",\n",
    "                    prev_layer=pipe.model.get_submodule(_n.replace(\"layer_norm2\", \"mlp\", -1)),\n",
    "                )\n",
    "    return _hp\n",
    "\n",
    "with DmxSLaNCRecipe(hp_gen).applied_to(pipe.model):\n",
    "    print(\"SLaNC done!\")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "[pipe(**_tc) for _tc in task_cases]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
