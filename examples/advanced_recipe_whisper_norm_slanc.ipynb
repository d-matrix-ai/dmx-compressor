{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58301fd",
   "metadata": {},
   "source": [
    "## Example ADVANCED mode recipe - normalization layer extra parameters tuning by SLaNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7acd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import copy\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from dmx.compressor.modeling import DmxModel\n",
    "\n",
    "def normalize(processor, text):\n",
    "    try:\n",
    "        res = processor.tokenizer.normalize(text)\n",
    "    except:\n",
    "        res = text.lower().strip()\n",
    "    return res\n",
    "\n",
    "def run_evaluation(pipe, dataset_list, processor,wer_metric,eval_name):\n",
    "    \"\"\"Helper function to run evaluation and return predictions/references\"\"\"\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    print(f\"Evaluating on {len(dataset_list)} samples...\")\n",
    "    \n",
    "    for i, sample in enumerate(dataset_list):\n",
    "        if i % 1 == 0:\n",
    "            print(f\"Processed {i}/{len(dataset_list)} samples\")\n",
    "\n",
    "        audio = sample[\"audio\"][\"array\"]\n",
    "        ground_truth = sample[\"text\"]\n",
    "\n",
    "        result = pipe(audio, return_timestamps=True)\n",
    "        prediction = result[\"text\"]\n",
    "\n",
    "        predictions.append(normalize(processor, prediction))\n",
    "        references.append(normalize(processor, ground_truth))\n",
    "    wer_score = wer_metric.compute(predictions=predictions, references=references)\n",
    "    print(f'***********{eval_name}\\n prediction: {predictions} \\n references: {references} \\n wer: {wer_score}')\n",
    "    return predictions, references , wer_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32146a0",
   "metadata": {},
   "source": [
    "\n",
    "1. Instantiate a `torch` model from source, HF hub in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65349518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 2 samples...\n",
      "Processed 0/2 samples\n",
      "Processed 1/2 samples\n",
      "***********vanilla\n",
      " prediction: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " references: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " wer: 0.0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "wer_metric = load(\"wer\")\n",
    "model_id = \"openai/whisper-medium\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model = model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "task = \"automatic-speech-recognition\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"librispeech_asr\", \"clean\", split=\"validation\", streaming=True, trust_remote_code=True\n",
    ")\n",
    "dataset = dataset.take(2)\n",
    "dataset_list = list(dataset)\n",
    "predictions_gt, references_gt, wer_gt = run_evaluation(pipe, dataset_list, processor, wer_metric, 'vanilla')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1ea08",
   "metadata": {},
   "source": [
    "2. Transform into `DmxModel`; this does not change the functional behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea78b5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 2 samples...\n",
      "Processed 0/2 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/2 samples\n",
      "***********baseline\n",
      " prediction: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " references: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " wer: 0.0\n"
     ]
    }
   ],
   "source": [
    "pipe.model = DmxModel.from_torch(pipe.model)\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "predictions_baseline, references_baseline, wer_baseline = run_evaluation(pipe, dataset_list, processor, wer_metric, 'baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d57ed5",
   "metadata": {},
   "source": [
    "3. Configure to BASIC mode; this should bring in all VSIMD approximations with default config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2de369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 2 samples...\n",
      "Processed 0/2 samples\n",
      "Processed 1/2 samples\n",
      "***********basic\n",
      " prediction: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " references: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " wer: 0.0\n"
     ]
    }
   ],
   "source": [
    "pipe.model.to_basic_mode()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "predictions_basic, references_basic, wer_basic = run_evaluation(pipe, dataset_list, processor, wer_metric, 'basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db9d4f",
   "metadata": {},
   "source": [
    "4. SLaNC calibrate `LayerNorm` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288e70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm is 32.99658203125\n",
      "Norm is 25.339387893676758\n",
      "Norm is 25.267427444458008\n",
      "Norm is 24.136276245117188\n",
      "Norm is 28.710100173950195\n",
      "Norm is 29.268850326538086\n",
      "Norm is 32.396549224853516\n",
      "Norm is 29.621387481689453\n",
      "Norm is 29.464366912841797\n",
      "Norm is 30.218650817871094\n",
      "Norm is 29.11838150024414\n",
      "Norm is 32.09354782104492\n",
      "Norm is 32.847068786621094\n",
      "Norm is 34.551700592041016\n",
      "Norm is 37.62411117553711\n",
      "Norm is 37.165462493896484\n",
      "Norm is 35.93863296508789\n",
      "Norm is 42.9462890625\n",
      "Norm is 37.44207000732422\n",
      "Norm is 38.32508087158203\n",
      "Norm is 46.133480072021484\n",
      "Norm is 45.95112609863281\n",
      "Norm is 39.404441833496094\n",
      "Norm is 50.06367492675781\n",
      "Norm is 35.80278015136719\n",
      "Norm is 19.66062355041504\n",
      "Norm is 11.302202224731445\n",
      "Norm is 35.44587326049805\n",
      "Norm is 8.609440803527832\n",
      "Norm is 22.760784149169922\n",
      "Norm is 11.468527793884277\n",
      "Norm is 30.196537017822266\n",
      "Norm is 19.79102325439453\n",
      "Norm is 28.874479293823242\n",
      "Norm is 31.28667449951172\n",
      "Norm is 49.02684783935547\n",
      "Norm is 24.505537033081055\n",
      "Norm is 34.34408950805664\n",
      "Norm is 32.893524169921875\n",
      "Norm is 50.53483200073242\n",
      "Norm is 30.957571029663086\n",
      "Norm is 49.24967956542969\n",
      "Norm is 28.790985107421875\n",
      "Norm is 44.068050384521484\n",
      "Norm is 38.77299880981445\n",
      "Norm is 42.9657096862793\n",
      "Norm is 39.90385055541992\n",
      "Norm is 27.238927841186523\n",
      "Norm is 34.0452880859375\n",
      "Norm is 31.146915435791016\n",
      "Norm is 37.36491775512695\n",
      "Norm is 39.29998016357422\n",
      "Norm is 42.55387496948242\n",
      "Norm is 36.8095817565918\n",
      "Norm is 43.9892463684082\n",
      "Norm is 34.42967987060547\n",
      "Norm is 42.787513732910156\n",
      "Norm is 41.42414855957031\n",
      "Norm is 39.94913101196289\n",
      "Norm is 39.59238815307617\n",
      "Norm is 43.27126693725586\n",
      "Norm is 37.651283264160156\n",
      "Norm is 39.29023742675781\n",
      "Norm is 36.68191146850586\n",
      "Norm is 37.31355667114258\n",
      "Norm is 37.671531677246094\n",
      "Norm is 41.21095657348633\n",
      "Norm is 38.23776626586914\n",
      "Norm is 39.81140899658203\n",
      "Norm is 42.2183837890625\n",
      "Norm is 33.53016662597656\n",
      "Norm is 34.825923919677734\n",
      "SLaNC done!\n",
      "Evaluating on 2 samples...\n",
      "Processed 0/2 samples\n",
      "Processed 1/2 samples\n",
      "***********basic_slanc\n",
      " prediction: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " references: ['he was in a fevered state of mind owing to the blight his wife is action threatened to cast upon his entire future', 'he would have to pay her the money which she would now regularly demand or there would be trouble it did not matter what he did'] \n",
      " wer: 0.0\n"
     ]
    }
   ],
   "source": [
    "from dmx.compressor import nn\n",
    "from dmx.compressor.modeling import DmxModule\n",
    "import re\n",
    "from dmx.compressor.advanced_recipe import (\n",
    "    DmxSLaNCHyperparams,\n",
    "    DmxSLaNCRecipe,\n",
    ")\n",
    "\n",
    "\n",
    "def hp_gen(_model) -> dict:\n",
    "    _hp = {}\n",
    "    \n",
    "    complete_gm = list(_model._gms.values())[0]\n",
    "    named_dmx_modules = [(n,m) for (n,m) in complete_gm.named_modules() if isinstance(m, DmxModule)]\n",
    "\n",
    "    for _n, _m in named_dmx_modules:\n",
    "        if isinstance(_m, nn.LayerNorm):\n",
    "            if \".layer_norm\" in _n:\n",
    "                # final layer norm\n",
    "                layers = pipe.model.get_submodule(_n.replace(\".layer_norm\", \".layers\", -1))\n",
    "                layers = list(layers.children())\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_mlp\",\n",
    "                    mlp_type=\"standard\",\n",
    "                    device=_m.weight.device,\n",
    "                    prev_ln_weight=layers[-1].final_layer_norm,\n",
    "                    fc1=layers[-1].fc1,\n",
    "                    fc2=layers[-1].fc2\n",
    "                )\n",
    "            elif \"self_attn_layer_norm\" in _n and \".0.\" not in _n:\n",
    "                layer_num = int(''.join(re.findall(r'\\.\\d+\\.', _n)).replace(\".\", \"\", -1))\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_mlp\",\n",
    "                    mlp_type=\"standard\",\n",
    "                    device=_m.weight.device,\n",
    "                    prev_ln_weight=pipe.model.get_submodule(\n",
    "                        _n.replace(\"self_attn_layer_norm\", \"final_layer_norm\", -1)\n",
    "                        .replace(\".\" + str(layer_num) + \".\", \".\" + str(layer_num - 1) + \".\", -1)),\n",
    "                    fc1=pipe.model.get_submodule(\n",
    "                        _n.replace(\"self_attn_layer_norm\", \"fc1\", -1)\n",
    "                        .replace(\".\" + str(layer_num) + \".\", \".\" + str(layer_num - 1) + \".\", -1)),\n",
    "                    fc2=pipe.model.get_submodule(\n",
    "                        _n.replace(\"self_attn_layer_norm\", \"fc2\", -1)\n",
    "                        .replace(\".\" + str(layer_num) + \".\", \".\" + str(layer_num - 1) + \".\", -1))\n",
    "                )\n",
    "            elif \"encoder_attn_layer_norm\" in _n:\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_attn\",\n",
    "                    device=_m.weight.device,\n",
    "                    prev_ln_weight=pipe.model.get_submodule(\n",
    "                        _n.replace(\"encoder_attn_layer_norm\", \"self_attn_layer_norm\", -1)),\n",
    "                    v_proj=pipe.model.get_submodule(\n",
    "                        _n.replace(\"encoder_attn_layer_norm\", \"self_attn.v_proj\", -1)),\n",
    "                    o_proj=pipe.model.get_submodule(\n",
    "                        _n.replace(\"encoder_attn_layer_norm\", \"self_attn.out_proj\", -1))\n",
    "                )\n",
    "            elif \"final_layer_norm\" in _n:\n",
    "                if \".encoder.\" in _n:\n",
    "                    prev_ln_weight = pipe.model.get_submodule(\n",
    "                        _n.replace(\"final_layer_norm\", \"self_attn_layer_norm\", -1)\n",
    "                    )\n",
    "                    v_proj = pipe.model.get_submodule(\n",
    "                        _n.replace(\"final_layer_norm\", \"self_attn.v_proj\", -1)\n",
    "                    )\n",
    "                    o_proj = pipe.model.get_submodule(\n",
    "                        _n.replace(\"final_layer_norm\", \"self_attn.out_proj\", -1)\n",
    "                    )\n",
    "                elif \".decoder.\" in _n:\n",
    "                    prev_ln_weight = pipe.model.get_submodule(\n",
    "                        _n.replace(\"final_layer_norm\", \"encoder_attn_layer_norm\", -1)\n",
    "                    )\n",
    "                    v_proj=pipe.model.get_submodule(\n",
    "                        _n.replace(\".decoder.\", \".encoder.\", -1)\n",
    "                        .replace(\"final_layer_norm\", \"self_attn.v_proj\", -1)\n",
    "                    )\n",
    "                    o_proj=pipe.model.get_submodule(\n",
    "                        _n.replace(\"final_layer_norm\", \"encoder_attn.out_proj\", -1)\n",
    "                    )\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"post_attn\",\n",
    "                    device=_m.weight.device,\n",
    "                    prev_ln_weight=prev_ln_weight,\n",
    "                    v_proj=v_proj,\n",
    "                    o_proj=o_proj\n",
    "                )\n",
    "            elif \"self_attn_layer_norm\" in _n and \".0.\" in _n:\n",
    "                _hp[_m] = DmxSLaNCHyperparams(\n",
    "                    position=\"first\",\n",
    "                    device=_m.weight.device\n",
    "                )\n",
    "    return _hp\n",
    "\n",
    "with DmxSLaNCRecipe(hp_gen).applied_to(pipe.model):\n",
    "    print(\"SLaNC done!\")\n",
    "\n",
    "from dmx.compressor.modeling.model import DmxConfig\n",
    "\n",
    "complete_gm = list(pipe.model._gms.values())[0]\n",
    "all_modules_config  = DmxConfig({'_gm.'+n:m.dmx_config() for n,m in complete_gm.named_modules() if isinstance(m,DmxModule)})\n",
    "pipe.model.configure(all_modules_config)\n",
    "\n",
    "predictions_slanc,references_slanc,wer_slanc = run_evaluation(pipe,dataset_list,processor,wer_metric,'basic_slanc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e641f99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: model.encoder.layers.0.self_attn_layer_norm, norm: {'norm': 1.0}\n",
      "Name: model.encoder.layers.0.final_layer_norm, norm: {'norm': tensor(0.0303, device='cuda:0')}\n",
      "Name: model.encoder.layers.1.self_attn_layer_norm, norm: {'norm': tensor(0.0300, device='cuda:0')}\n",
      "Name: model.encoder.layers.1.final_layer_norm, norm: {'norm': tensor(0.0395, device='cuda:0')}\n",
      "Name: model.encoder.layers.2.self_attn_layer_norm, norm: {'norm': tensor(0.0313, device='cuda:0')}\n",
      "Name: model.encoder.layers.2.final_layer_norm, norm: {'norm': tensor(0.0396, device='cuda:0')}\n",
      "Name: model.encoder.layers.3.self_attn_layer_norm, norm: {'norm': tensor(0.0302, device='cuda:0')}\n",
      "Name: model.encoder.layers.3.final_layer_norm, norm: {'norm': tensor(0.0414, device='cuda:0')}\n",
      "Name: model.encoder.layers.4.self_attn_layer_norm, norm: {'norm': tensor(0.0315, device='cuda:0')}\n",
      "Name: model.encoder.layers.4.final_layer_norm, norm: {'norm': tensor(0.0348, device='cuda:0')}\n",
      "Name: model.encoder.layers.5.self_attn_layer_norm, norm: {'norm': tensor(0.0329, device='cuda:0')}\n",
      "Name: model.encoder.layers.5.final_layer_norm, norm: {'norm': tensor(0.0342, device='cuda:0')}\n",
      "Name: model.encoder.layers.6.self_attn_layer_norm, norm: {'norm': tensor(0.0306, device='cuda:0')}\n",
      "Name: model.encoder.layers.6.final_layer_norm, norm: {'norm': tensor(0.0309, device='cuda:0')}\n",
      "Name: model.encoder.layers.7.self_attn_layer_norm, norm: {'norm': tensor(0.0357, device='cuda:0')}\n",
      "Name: model.encoder.layers.7.final_layer_norm, norm: {'norm': tensor(0.0338, device='cuda:0')}\n",
      "Name: model.encoder.layers.8.self_attn_layer_norm, norm: {'norm': tensor(0.0088, device='cuda:0')}\n",
      "Name: model.encoder.layers.8.final_layer_norm, norm: {'norm': tensor(0.0339, device='cuda:0')}\n",
      "Name: model.encoder.layers.9.self_attn_layer_norm, norm: {'norm': tensor(0.0292, device='cuda:0')}\n",
      "Name: model.encoder.layers.9.final_layer_norm, norm: {'norm': tensor(0.0331, device='cuda:0')}\n",
      "Name: model.encoder.layers.10.self_attn_layer_norm, norm: {'norm': tensor(0.0294, device='cuda:0')}\n",
      "Name: model.encoder.layers.10.final_layer_norm, norm: {'norm': tensor(0.0343, device='cuda:0')}\n",
      "Name: model.encoder.layers.11.self_attn_layer_norm, norm: {'norm': tensor(0.0294, device='cuda:0')}\n",
      "Name: model.encoder.layers.11.final_layer_norm, norm: {'norm': tensor(0.0312, device='cuda:0')}\n",
      "Name: model.encoder.layers.12.self_attn_layer_norm, norm: {'norm': tensor(0.0355, device='cuda:0')}\n",
      "Name: model.encoder.layers.12.final_layer_norm, norm: {'norm': tensor(0.0304, device='cuda:0')}\n",
      "Name: model.encoder.layers.13.self_attn_layer_norm, norm: {'norm': tensor(0.0373, device='cuda:0')}\n",
      "Name: model.encoder.layers.13.final_layer_norm, norm: {'norm': tensor(0.0289, device='cuda:0')}\n",
      "Name: model.encoder.layers.14.self_attn_layer_norm, norm: {'norm': tensor(0.0349, device='cuda:0')}\n",
      "Name: model.encoder.layers.14.final_layer_norm, norm: {'norm': tensor(0.0266, device='cuda:0')}\n",
      "Name: model.encoder.layers.15.self_attn_layer_norm, norm: {'norm': tensor(0.0361, device='cuda:0')}\n",
      "Name: model.encoder.layers.15.final_layer_norm, norm: {'norm': tensor(0.0269, device='cuda:0')}\n",
      "Name: model.encoder.layers.16.self_attn_layer_norm, norm: {'norm': tensor(0.0305, device='cuda:0')}\n",
      "Name: model.encoder.layers.16.final_layer_norm, norm: {'norm': tensor(0.0278, device='cuda:0')}\n",
      "Name: model.encoder.layers.17.self_attn_layer_norm, norm: {'norm': tensor(0.0224, device='cuda:0')}\n",
      "Name: model.encoder.layers.17.final_layer_norm, norm: {'norm': tensor(0.0233, device='cuda:0')}\n",
      "Name: model.encoder.layers.18.self_attn_layer_norm, norm: {'norm': tensor(0.0237, device='cuda:0')}\n",
      "Name: model.encoder.layers.18.final_layer_norm, norm: {'norm': tensor(0.0267, device='cuda:0')}\n",
      "Name: model.encoder.layers.19.self_attn_layer_norm, norm: {'norm': tensor(0.0266, device='cuda:0')}\n",
      "Name: model.encoder.layers.19.final_layer_norm, norm: {'norm': tensor(0.0261, device='cuda:0')}\n",
      "Name: model.encoder.layers.20.self_attn_layer_norm, norm: {'norm': tensor(0.0234, device='cuda:0')}\n",
      "Name: model.encoder.layers.20.final_layer_norm, norm: {'norm': tensor(0.0217, device='cuda:0')}\n",
      "Name: model.encoder.layers.21.self_attn_layer_norm, norm: {'norm': tensor(0.0155, device='cuda:0')}\n",
      "Name: model.encoder.layers.21.final_layer_norm, norm: {'norm': tensor(0.0218, device='cuda:0')}\n",
      "Name: model.encoder.layers.22.self_attn_layer_norm, norm: {'norm': tensor(0.0097, device='cuda:0')}\n",
      "Name: model.encoder.layers.22.final_layer_norm, norm: {'norm': tensor(0.0254, device='cuda:0')}\n",
      "Name: model.encoder.layers.23.self_attn_layer_norm, norm: {'norm': tensor(0.0095, device='cuda:0')}\n",
      "Name: model.encoder.layers.23.final_layer_norm, norm: {'norm': tensor(0.0200, device='cuda:0')}\n",
      "Name: model.encoder.layer_norm, norm: {'norm': tensor(0.0186, device='cuda:0')}\n",
      "Name: model.decoder.layers.0.self_attn_layer_norm, norm: {'norm': 1.0}\n",
      "Name: model.decoder.layers.0.encoder_attn_layer_norm, norm: {'norm': tensor(0.0279, device='cuda:0')}\n",
      "Name: model.decoder.layers.0.final_layer_norm, norm: {'norm': tensor(0.0509, device='cuda:0')}\n",
      "Name: model.decoder.layers.1.self_attn_layer_norm, norm: {'norm': tensor(0.0479, device='cuda:0')}\n",
      "Name: model.decoder.layers.1.encoder_attn_layer_norm, norm: {'norm': tensor(0.0885, device='cuda:0')}\n",
      "Name: model.decoder.layers.1.final_layer_norm, norm: {'norm': tensor(0.0282, device='cuda:0')}\n",
      "Name: model.decoder.layers.2.self_attn_layer_norm, norm: {'norm': tensor(0.0445, device='cuda:0')}\n",
      "Name: model.decoder.layers.2.encoder_attn_layer_norm, norm: {'norm': tensor(0.1162, device='cuda:0')}\n",
      "Name: model.decoder.layers.2.final_layer_norm, norm: {'norm': tensor(0.0439, device='cuda:0')}\n",
      "Name: model.decoder.layers.3.self_attn_layer_norm, norm: {'norm': tensor(0.0415, device='cuda:0')}\n",
      "Name: model.decoder.layers.3.encoder_attn_layer_norm, norm: {'norm': tensor(0.0872, device='cuda:0')}\n",
      "Name: model.decoder.layers.3.final_layer_norm, norm: {'norm': tensor(0.0331, device='cuda:0')}\n",
      "Name: model.decoder.layers.4.self_attn_layer_norm, norm: {'norm': tensor(0.0191, device='cuda:0')}\n",
      "Name: model.decoder.layers.4.encoder_attn_layer_norm, norm: {'norm': tensor(0.0505, device='cuda:0')}\n",
      "Name: model.decoder.layers.4.final_layer_norm, norm: {'norm': tensor(0.0346, device='cuda:0')}\n",
      "Name: model.decoder.layers.5.self_attn_layer_norm, norm: {'norm': tensor(0.0355, device='cuda:0')}\n",
      "Name: model.decoder.layers.5.encoder_attn_layer_norm, norm: {'norm': tensor(0.0320, device='cuda:0')}\n",
      "Name: model.decoder.layers.5.final_layer_norm, norm: {'norm': tensor(0.0204, device='cuda:0')}\n",
      "Name: model.decoder.layers.6.self_attn_layer_norm, norm: {'norm': tensor(0.0476, device='cuda:0')}\n",
      "Name: model.decoder.layers.6.encoder_attn_layer_norm, norm: {'norm': tensor(0.0408, device='cuda:0')}\n",
      "Name: model.decoder.layers.6.final_layer_norm, norm: {'norm': tensor(0.0291, device='cuda:0')}\n",
      "Name: model.decoder.layers.7.self_attn_layer_norm, norm: {'norm': tensor(0.0417, device='cuda:0')}\n",
      "Name: model.decoder.layers.7.encoder_attn_layer_norm, norm: {'norm': tensor(0.0304, device='cuda:0')}\n",
      "Name: model.decoder.layers.7.final_layer_norm, norm: {'norm': tensor(0.0198, device='cuda:0')}\n",
      "Name: model.decoder.layers.8.self_attn_layer_norm, norm: {'norm': tensor(0.0366, device='cuda:0')}\n",
      "Name: model.decoder.layers.8.encoder_attn_layer_norm, norm: {'norm': tensor(0.0323, device='cuda:0')}\n",
      "Name: model.decoder.layers.8.final_layer_norm, norm: {'norm': tensor(0.0203, device='cuda:0')}\n",
      "Name: model.decoder.layers.9.self_attn_layer_norm, norm: {'norm': tensor(0.0359, device='cuda:0')}\n",
      "Name: model.decoder.layers.9.encoder_attn_layer_norm, norm: {'norm': tensor(0.0347, device='cuda:0')}\n",
      "Name: model.decoder.layers.9.final_layer_norm, norm: {'norm': tensor(0.0227, device='cuda:0')}\n",
      "Name: model.decoder.layers.10.self_attn_layer_norm, norm: {'norm': tensor(0.0368, device='cuda:0')}\n",
      "Name: model.decoder.layers.10.encoder_attn_layer_norm, norm: {'norm': tensor(0.0258, device='cuda:0')}\n",
      "Name: model.decoder.layers.10.final_layer_norm, norm: {'norm': tensor(0.0233, device='cuda:0')}\n",
      "Name: model.decoder.layers.11.self_attn_layer_norm, norm: {'norm': tensor(0.0388, device='cuda:0')}\n",
      "Name: model.decoder.layers.11.encoder_attn_layer_norm, norm: {'norm': tensor(0.0251, device='cuda:0')}\n",
      "Name: model.decoder.layers.11.final_layer_norm, norm: {'norm': tensor(0.0367, device='cuda:0')}\n",
      "Name: model.decoder.layers.12.self_attn_layer_norm, norm: {'norm': tensor(0.0400, device='cuda:0')}\n",
      "Name: model.decoder.layers.12.encoder_attn_layer_norm, norm: {'norm': tensor(0.0294, device='cuda:0')}\n",
      "Name: model.decoder.layers.12.final_layer_norm, norm: {'norm': tensor(0.0321, device='cuda:0')}\n",
      "Name: model.decoder.layers.13.self_attn_layer_norm, norm: {'norm': tensor(0.0406, device='cuda:0')}\n",
      "Name: model.decoder.layers.13.encoder_attn_layer_norm, norm: {'norm': tensor(0.0268, device='cuda:0')}\n",
      "Name: model.decoder.layers.13.final_layer_norm, norm: {'norm': tensor(0.0254, device='cuda:0')}\n",
      "Name: model.decoder.layers.14.self_attn_layer_norm, norm: {'norm': tensor(0.0402, device='cuda:0')}\n",
      "Name: model.decoder.layers.14.encoder_attn_layer_norm, norm: {'norm': tensor(0.0235, device='cuda:0')}\n",
      "Name: model.decoder.layers.14.final_layer_norm, norm: {'norm': tensor(0.0272, device='cuda:0')}\n",
      "Name: model.decoder.layers.15.self_attn_layer_norm, norm: {'norm': tensor(0.0383, device='cuda:0')}\n",
      "Name: model.decoder.layers.15.encoder_attn_layer_norm, norm: {'norm': tensor(0.0227, device='cuda:0')}\n",
      "Name: model.decoder.layers.15.final_layer_norm, norm: {'norm': tensor(0.0290, device='cuda:0')}\n",
      "Name: model.decoder.layers.16.self_attn_layer_norm, norm: {'norm': tensor(0.0313, device='cuda:0')}\n",
      "Name: model.decoder.layers.16.encoder_attn_layer_norm, norm: {'norm': tensor(0.0234, device='cuda:0')}\n",
      "Name: model.decoder.layers.16.final_layer_norm, norm: {'norm': tensor(0.0241, device='cuda:0')}\n",
      "Name: model.decoder.layers.17.self_attn_layer_norm, norm: {'norm': tensor(0.0368, device='cuda:0')}\n",
      "Name: model.decoder.layers.17.encoder_attn_layer_norm, norm: {'norm': tensor(0.0250, device='cuda:0')}\n",
      "Name: model.decoder.layers.17.final_layer_norm, norm: {'norm': tensor(0.0253, device='cuda:0')}\n",
      "Name: model.decoder.layers.18.self_attn_layer_norm, norm: {'norm': tensor(0.0362, device='cuda:0')}\n",
      "Name: model.decoder.layers.18.encoder_attn_layer_norm, norm: {'norm': tensor(0.0231, device='cuda:0')}\n",
      "Name: model.decoder.layers.18.final_layer_norm, norm: {'norm': tensor(0.0266, device='cuda:0')}\n",
      "Name: model.decoder.layers.19.self_attn_layer_norm, norm: {'norm': tensor(0.0352, device='cuda:0')}\n",
      "Name: model.decoder.layers.19.encoder_attn_layer_norm, norm: {'norm': tensor(0.0255, device='cuda:0')}\n",
      "Name: model.decoder.layers.19.final_layer_norm, norm: {'norm': tensor(0.0273, device='cuda:0')}\n",
      "Name: model.decoder.layers.20.self_attn_layer_norm, norm: {'norm': tensor(0.0353, device='cuda:0')}\n",
      "Name: model.decoder.layers.20.encoder_attn_layer_norm, norm: {'norm': tensor(0.0268, device='cuda:0')}\n",
      "Name: model.decoder.layers.20.final_layer_norm, norm: {'norm': tensor(0.0265, device='cuda:0')}\n",
      "Name: model.decoder.layers.21.self_attn_layer_norm, norm: {'norm': tensor(0.0386, device='cuda:0')}\n",
      "Name: model.decoder.layers.21.encoder_attn_layer_norm, norm: {'norm': tensor(0.0243, device='cuda:0')}\n",
      "Name: model.decoder.layers.21.final_layer_norm, norm: {'norm': tensor(0.0262, device='cuda:0')}\n",
      "Name: model.decoder.layers.22.self_attn_layer_norm, norm: {'norm': tensor(0.0297, device='cuda:0')}\n",
      "Name: model.decoder.layers.22.encoder_attn_layer_norm, norm: {'norm': tensor(0.0251, device='cuda:0')}\n",
      "Name: model.decoder.layers.22.final_layer_norm, norm: {'norm': tensor(0.0237, device='cuda:0')}\n",
      "Name: model.decoder.layers.23.self_attn_layer_norm, norm: {'norm': tensor(0.0238, device='cuda:0')}\n",
      "Name: model.decoder.layers.23.encoder_attn_layer_norm, norm: {'norm': tensor(0.0298, device='cuda:0')}\n",
      "Name: model.decoder.layers.23.final_layer_norm, norm: {'norm': tensor(0.0287, device='cuda:0')}\n",
      "Name: model.decoder.layer_norm, norm: {'norm': tensor(0.0226, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "named_dmx_modules = [(n,m) for (n,m) in complete_gm.named_modules() if isinstance(m, DmxModule)]\n",
    "for _n, _m in named_dmx_modules:\n",
    "    if isinstance(_m, nn.LayerNorm):\n",
    "        print(f\"Name: {_n}, norm: {_m.approximator.function.extra_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
