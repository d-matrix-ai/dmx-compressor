{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "task_spec = dict(\n",
    "    images=\"http://images.cocodataset.org/val2017/000000039769.jpg\", \n",
    "    candidate_labels=[\n",
    "        \"a cat\", \n",
    "        \"two cats\", \n",
    "        \"a dog\", \n",
    "        \"two dogs\", \n",
    "        \"a dog and a cat\",\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original inference\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"zero-shot-image-classification\", \n",
    "    model=model_id,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "pipe(**task_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these additional lines before transformation/configuration to map Conv2d to our alternative version\n",
    "from dmx.compressor.modeling.nn import experimental\n",
    "from dmx.compressor.fx.transformer.utils import dmx_aware_mapping\n",
    "\n",
    "dmx_aware_mapping[\"torch.nn.modules.conv.Conv2d\"] = experimental.Conv2d\n",
    "\n",
    "# ---\n",
    "# transformation and configuration\n",
    "from dmx.compressor import DmxModel\n",
    "\n",
    "pipe.model = DmxModel.from_torch(pipe.model)\n",
    "pipe.model.to_basic_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(**task_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model.dmx_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QdQ transform pipe.model._gm and show there is no conv2d in encoder\n",
    "from dmx.compressor.fx.transform import make_compiler_graph\n",
    "compiler_graph = make_compiler_graph(pipe.model._gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._gm.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler_graph.graph.print_tabular()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltools",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
