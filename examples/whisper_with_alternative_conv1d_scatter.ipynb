{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get whisper to `dmx.compiler` with alternative `Conv1d` subgraph (scatter implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"openai/whisper-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original inference\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\", \n",
    "    model=model_id,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "pipe(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these additional lines before transformation/configuration to map Conv1d to our alternative version\n",
    "from dmx.compressor.modeling.nn import experimental\n",
    "from dmx.compressor.fx.transformer.utils import dmx_aware_mapping\n",
    "\n",
    "dmx_aware_mapping[\"torch.nn.modules.conv.Conv1d\"] = experimental.Conv1dScatter\n",
    "\n",
    "# ---\n",
    "# transformation and configuration\n",
    "from dmx.compressor import DmxModel\n",
    "\n",
    "pipe.model = DmxModel.from_torch(pipe.model)\n",
    "pipe.model.to_basic_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pipe(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model.dmx_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmx_aware_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pipe.model._gms``` is a dictionary that contains all GraphModules created so far, with their input signature reprensentation as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._gms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below inputs has the same signature as the first forward pass in generation pipe, hence we already have the corresponding gm and it will be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a forward that triggers JIT tracing through encoder\n",
    "inputs = {\n",
    "    \"input_features\": torch.rand(1, 80, 3000).to(\"cuda\"),\n",
    "    \"decoder_input_ids\": torch.tensor([[50258]], device=\"cuda\"),\n",
    "}\n",
    "output = pipe.model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pipe.model.make_compiler_graphs()``` is a function to go through all gms in ```model._gms``` and turn them to compiler graphs, which will be stored in ```pipe.model._compiler_graphs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dmx.ops\n",
    "pipe.model.make_compiler_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._compiler_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first gm contains the encoder, which contains the Conv1ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(pipe.model._gms.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._gms[key].graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model._compiler_graphs[key].graph.print_tabular()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
